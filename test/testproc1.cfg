# Configuration file for the daily processing code
#
# This is read and processed using the LINZ::GNSS::Config module.
# See 'man LINZ::GNSS::Config' for information about string substitution
#
# Configuration items may include ${xxx} that are replaced by (in order of
# preference)
#    command line parameters xxx=yyy
#    other configuration items
#    environment variable xxx
#
# ${configdir} is defined as the directory of this configuration file unless
# overridden by another option
# ${pid_#} expands to the process id padded with 0 or left trimmed to #
# characters
# ${yyyy} and ${ddd} expand to the currently processing day and year, and
# otherwise are invalid. Also ${mm} and ${dd} for month and day number.
# Date variables can be offset by a number of days, eg ${yyyy+14}
#
# A variable can be substituted with results for multiple days by
# the syntax
#
# value for -14 to 0 [step #] [if exists] [need #] xxxxxxxxx
#
# which will return value with expanded values for the current day -14 to the
# current day. Note that to use value in another configuration item it must
# be specified as $[value] rather than with ${value}

# Parameters can have alternative configuration specified by suffix -cfg.
#
# For example
#   start_date -14
#   start_date-rapid -2
#
# Will use -14 for start_date by default, and -2 if the script is run
# with config=rapid as a suffix on the command line.

# Working directories.  Paths are relative to the location of this
# configuration file.

# Location of results files, status files for daily processing.
# Allows defining a base directory with a subdirectory.  Filename is
# relative to base directory (on file system), or relative to S3 prefix

subdir test
base_directory ${configdir}/testprocdir${subdir?/}${subdir}
target_directory ${yyyy}/${ddd}

# If files are to be stored on AWS S3, then s3 bucket and s3_dir can be
# defined.  Otherwise storage is in the local file system.  status files
# (lock, success, fail) are tested in S3 if it being used)

s3_bucket dev-linz-geodesy-test
s3_prefix processor${subdir?/}${subdir}
# s3_aws_client /usr/bin/aws
s3_aws_parameters --profile linz-geodesy-nonprod

# Lock file - used to prevent two jobs trying to work on the same task.
# Lock expiry is the time out for the lock - a lock that is older than this
# is ignored.

lock_file daily_processing.lock
lock_expiry_days 0.9

# Completed file - used to flag that the daily processing has run for
# the directory successfully.
# The script will not run on a directory containing this flag.

complete_file daily_processing.complete

# Fail file - used to flag that the processing has run for the directory
# but not succeeded.  The script may run in that directory again subject
# to the retry parameters.

fail_file daily_processing.failed

# Skip files - names of one or more files which signal that the script is not
# to run.

skip_files

# Failed jobs may be retried after retry_interval, but will never rerun
# for jobs greater than retry_max_age days.  (Assume that nothing will
# change to fix them after that)

retry_max_age_days  30
retry_interval_days 0.9

# Start and end dates.
# Processing is done starting at the end date (most recent) back to
# the start date.  Dates may either by dd-mm-yyyy, yyyy-ddd,
# or -n (for n days before today).

start_date 2000/001
end_date -18

start_date-rapid -17
end_date-rapid -2

# Number of days to subtract for each day processed

date_increment 1

# Order of processing.  Options are forwards (from earliest date),
# backwards (from latest date), binary_fill (fills with scheme that
# aims to provide uniform coverage while filling), and random
# Default is backwards

processing_order backwards

# Limits on number of jobs.  0 = unlimited
# Maximum number of days is the maximum number of days that will be processed,
# not including days that don't need processing.
# Maximum run time defines the latest time after the script is initiated that
# it will start a new job. It is formatted as hh:mm

max_days_processed_per_run 0
max_runtime 0:00

# Maximum consecutive failures.  If this number of consecutive failures occurs then
# the processing is aborted and the failed status files are removed.  This assumes
# that there is some system failure rather than problems with individual days, so
# leaves the unprocessed days ready to run again. Missing or 0 will accept any number
# of failures.

max_consecutive_fails 0

# Prerequisite file(s).  If specified then days will be skipped if the
# specified files do not exist.  Prerequisite files can start be specified
# as ~/filename to specifiy a file in the target directory

prerequisite_files

max_consecutive_prerequisite_fails

# Clean on start setting controls which files are removed from the
# result directory when the jobs starts.  The default is just to remove
# the job management files (above).
#
# Use "all" to remove all files (except the lock file)
# Use "none" to leave all other files unaltered
# Use file names (possibly wildcarded) for specific files.

clean_on_start all

# Optional name of a file to test for success of the processing run

test_success_file

# File that will stop the script if it exists

stop_file ${base_directory}/${configname}.stop

# =======================================================================
# The following items are used by the runBernesePcf function
#
# Note that when a PCF is run the SAVEDISK environment variable ($S) is set
# to point to the daily processor target directory.
#
# The name of the Bernese PCF to run (use NONE to skip bernese processing)

pcf          PNZDAILY

# ZIP file(s) containing files to unpack into user directory of the
# bernese environment of the job.  (eg compiled with get_pcf_files -z)

pcf_user_zip_file

# Campaign files copied before the PCF is run.  These are formatted as
# one file specification per line (use << EOD for multiple lines).
# Each line consists of the campaign directory (eg STA), the optional
# keyword "uncompress", and the name of one or more files separated by
# space characteers.
# Filename can contain the * and ? wildcards to copy multiple files.
# Use the "uncompress" keyword to uncompress gzipped (.gz)
# or compress (.Z) files. (Assumes the file names are terminated .gz or .Z)
#
# eg: RAW uncompress TEST${ddd}0.${yy}O.gz

pcf_campaign_files

# The name of the CPU file that will be used (default is UNIX.CPU)

pcf_cpufile  UNIX

# PCF parameters to override, written as
#  xxx1=yyy1 xxx2=yyy2 ...

pcf_params         V_ORBTYP=FINAL V_O=s
pcf_params-rapid   V_ORBTYP=RAPID V_O=r

# File used to confirm success of BPE run

pcf_test_success_file

# Bernese output can be saved either by saving the entire directory to
# a specified location (relative to the target directory), or by saving
# specific file.  In either case there are separate settings depending on
# whether the outcome was successful or not.

# Files that will be copied to the target directory if the PCF succeeds
# File can be suffixed ':gzip' or ':compress' to compress them after copying.

pcf_save_files   BPE/PNZDAILY.OUT
pcf_fail_save_files

# Directory into which to copy Bernese campaign files if the PCF fails.
# (Note: this is relative to the target directory for the daily process.
# Files are not copied if this is not saved).

pcf_copy_dir
pcf_fail_copy_dir fail_data

# By default the Bernese runtime environment is deleted once the script has finished.
# Use pcf_save_campaign_dir to leave it unchanged (though it may be overwritten by
# the campaign for subsequent days)

pcf_save_campaign_dir 0

# Pre-run and post run scripts.  These are run before and after the
# bernese job by the run_daily_processor script.
# When these are run the Bernese environment is configured,
# including the Bernese environment variables.  Three additional variables
# are defined
#
#    PROCESSOR_CAMPAIGN      The Bernese campaign id
#    PROCESSOR_CAMPAIGN_DIR  The Bernese campaign id (if it has not been deleted)
#    PROCESSOR_STATUS        (Only applies to the post_run script) either 0 or 1
#                            depending on whether the Bernese BPE script ran
#                            successfully or not.
#
# If a directory is not specified these are assumed to be in the same directory
# as the configuration file

# =======================================================================
# The following items may be run by the runScripts function
#
# If "none" then no script is run.
# If more than one script is to be run these can included using a <<EOD heredoc.
# Each line can specify a script name and parameters.
# If the script name is prefixed with perl: then it will be run as a perl script
# in the context of the processor using the perl "do" function, otherwise it
# will run as a normal command.
# The postrun_script has success or failure options.  If these are not explicitly
# defined for the actual status then the generic postrun_script will be used.

prerun_script  none
postrun_script none
postrun_script_success none
postrun_script_fail none

# =======================================================================
# Log settings are managed by the LINZ::GNSS::Config module.

logdir
logfile
logsettings info

# The logsettings can include the string [logfilename] which will be substituted with the name built from
# logdir and logfile.
#
# Instead of a full Log::Log4perl definition logsettings can simply be the log level, one of trace, debug,
# info, warn, error, or fatal.


# =======================================================================
# The following items may be used by the sendNotification function
#
# Email configuration.  Defines how messages are sent
#
# SMTP server to use (can include :port)

notification_smtp_server

# File from which server credentials are read.  If not specified then the
# script will assume that none is required.  The server name/port may also
# be read from this file if it is defined and exists.
# The file is formatted as:
#
# server the_server
# user the_user
# password xxxxxxx

notification_auth_file

# Address to send notifications to.  May include multiple address separated
# by commas

notification_email_address

# Address from which the notification is sent

notification_from_address

# Notification subject line. Notifications may be sent on success or failure.  The
# subject will be taken from the status specific message if it is defined, otherwise
# the generic message.  If both are blank then no message is sent for the status

notification_subject
notification_subject_success
notification_subject_fail

# Notification message text. Notifications may be sent on success or failure.  The
# text will be taken from the status specific message if it is defined, otherwise
# the generic message.  If both are blank then no message is sent for the status
#
# The text can include [text] for text included in the sendNotification function
# call, [info], [warning], and [error] for corresponding information recorded when
# processing the current day

notification_text
notification_text_success
notification_text_fail

