#!/usr/bin/perl 

eval 'exec /usr/bin/perl  -S $0 ${1+"$@"}'
    if 0; # not running under some shell

=head1 gnss_ftp_mirror

Simple ftp mirror script to recursely mirror files from a remote ftp site 
to a local directory.  

The script is designed to interrogate a GNSS archive type file system with 
directories and files named after year, day, station code etc.  

The configuration file defines the structure of the file name and path in
terms of these components.  As the files are downloaded they can be renamed
using these fields.  

The script looks for a range of files based on their age in days (actually
the age of the data, not the file).  For example it can download files 
with dates matching the last 30 days.

=head2 Synopsis:

 gnss_ftp_mirror.pl [options] config_file [item=value ...]

The parameters are the name of a configuration, and a set of configuration
values which override the values in the configuration file.

Options are:

=over

=item  -v            

Verbose mode - lists information about downloads etc

=item  -V            

More verbose mode - additional information only messages

=item -s ###        

Specify the start date for downloads as days before the current date.  eg -s 30
or in a GNSS date format eg 2014-050.

=item -e ###        

Specify the end date for downloads as days before the current date.  eg -s 30
or in a GNSS date format eg 2014-050.

=item -p ##

Specifies a pause in seconds between successive downloads.  This is to be kind
to the server!  Default is 1 second unless defined otherwise in the configuration
file

=item -r ##

Specifies the maximum runtime for in minutes.  Downloads will be aborted after this 
time.

=item -i

Ignore file size. If present then all matching files are downloaded.  
Otherwise files will not be downloaded if there is already an existing file
of the same size.

=item -c

Print an example configuration file

=back

=cut

use strict;
use Getopt::Std;
use URI;
use Net::FTP;
use Cwd qw(abs_path getcwd);
use File::Path;
use File::Copy;
use File::Temp qw(tempdir);
use Time::HiRes;
use Config::General;
use POSIX qw/strftime/;
use LINZ::RunBatch;
use LINZ::GNSS::Time qw/parse_gnss_date seconds_yearday time_elements seconds_ymdhms $SECS_PER_DAY/;

my $syntax=<<EOD;

Syntax: gnss_ftp_mirror.pl [-b|-B logfile] [options] config_file [item=value ...]

Options are:
   -b            Run in batch mode starting with 'at now'
   -B logfile    Run in batch mode with a specified log file
   -n            List downloaded files
   -v            Verbose mode
   -V            Even more verbose
   -s ###        Start date to download (days before now)
   -e ###        End date to download (days before now)
   -p ##         Reset pause between downloads
   -r ###        Maximum run time in minutes
   -i            Ignore file size - download all matching files
   -c            Print an example configuration file

EOD

#=====================================================================

my @months=('jan','feb','mar','apr','may','jun','jul','aug','sep','oct','nov','dec');
my @umonths=();
my @ccmonths=();
my @fullmonths=('january','february','march','april','may','june',
                'july','august','september','october','november','december');
my @ufmonths=();
my @cfmonths=();

foreach my $mon (@months) 
{
    push(@umonths,uc($mon));
    my $ccmon=$mon;
    substr($ccmon,0,1)=uc(substr($ccmon,0,1));
    push(@ccmonths,uc($mon));
}

foreach my $mon (@fullmonths) 
{
    push(@ufmonths,uc($mon));
    my $ccmon=$mon;
    substr($ccmon,0,1)=uc(substr($ccmon,0,1));
    push(@cfmonths,uc($mon));
}

my %patterns=(
    'yyyy' => '\d\d\d\d',
    'yy' =>   '\d\d',
    'hh' =>   '\d\d',
    'mm' =>   '\d\d',
    'mmm' =>  '('.join('|',@months).')',
    'Mmm' =>  '('.join('|',@ccmonths).')',
    'MMM' =>  '('.join('|',@umonths).')',
    'dd'  =>  '\d\d',
    'ddd' =>  '\d\d\d',
    'code' => '[a-z0-9]{4}',
    'CODE' => '[A-Z0-9]{4}',
    'Code' => '[A-Za-z0-9]{4}',
);

# Convert a time duration to seconds. Format is a number
# followed optionally by s,m,h,d for seconds, hours, minutes,
# days.  Default is minutes.

my %timeunitconv=(
    's' => 1,
    'm' => 60,
    'h' => 60*60,
    'd' => 60*60*24,
);

my $timespanre=qr/^\s*(\d+(?:\.\d*)?)\s*((?:s(?:econds?)?|m(?:inutes?)?|h(?:ours?)?|d(?:ays?)?)?)\s*$/;

sub timeToSeconds
{
    my($spanstr)=@_;
    $spanstr=lc($spanstr);
    return 0 if $spanstr !~ $timespanre;
    my $seconds=$1;
    my $units=substr($2 || 'm',0,1);
    $seconds *= $timeunitconv{$units};
    return $seconds;
}

#=================================================================
# Get options
my %opts;
getopts('Vvncis:e:p:r:',\%opts);

if( $opts{c} )
{
    printExampleConfig();
    exit();
}

my $verbose=$opts{V} ? 2 : $opts{v} ? 1 : 0;
my $listfiles=$opts{n};
my $ignoresize=$opts{i};

@ARGV >= 1 || die $syntax;

my $conffile=shift @ARGV;
die "Cannot find config file $conffile\n" if ! -e $conffile;

my %argconfig=();
foreach my $arg (@ARGV)
{
    die "Invalid configuration argument $arg: should be xxx=yyy"
        if $arg !~ /^(\w+)\=(.*)/;
    $argconfig{lc($1)} = $2;
}

my $confdir=abs_path($conffile);
$confdir =~ s/[^\\\/]*$//;
$confdir =~ s/[\\\/]$//;
$confdir = '.' if $confdir eq '';

my %config=Config::General->new(
    -ConfigFile=>$conffile,
    -LowerCaseNames=>1,
    -UseApacheInclude=>1,
    -IncludeRelative=>1 )->getall();

foreach my $k (keys %argconfig)
{
    $config{$k}=$argconfig{$k};
}

# Expand references in configuration

my %unresolved=();
foreach my $k (keys(%config))
{
    my $v=$config{$k};
    my $maxiterations=10;
    while( $maxiterations > 0 )
    {
        my $v0=$v;
        $v =~ s/(\{(\w+)\})/exists $config{lc($2)} ? $config{lc($2)} : $1/eg;
        $v =~ s/(\{ENV\:(\w+)\})/exists $ENV{$2} ? $ENV{$2} : $1/eg;
        $v =~ s/(\{(\w+)\})/! exists $patterns{$2} && exists $ENV{$2} ? $ENV{$2} : $1/eg;
        last if $v eq $v0;
    }
    foreach my $var ($v =~ /\{((?:ENV\:)\w+)\}/g)
    {
        $unresolved{$var}=1 if ! exists $patterns{$var};
    }
    $config{$k}=$v;
}
if( %unresolved )
{
    my $badvar=join(' ',sort keys %unresolved);
    die "The following configuration items are undefined: $badvar\n";
}

my $bucketname=$config{s3_bucket};
my $bucketprefix;
my $bucket;
my $localdir;
my $localsrc;
if( $bucketname )
{
    require LINZ::GNSS::AwsS3Bucket;
    $bucketprefix = $config{s3_prefix};
    $bucket = LINZ::GNSS::AwsS3Bucket->new(config_prefix=>'s3_',%config);
    $localsrc='temporary working directory';
    $localdir=tempdir(CLEANUP=>1)
}
else
{
    $localsrc = $config{localbasedirectory};
    $localdir = $localsrc;
    $localdir =~ s/^\~\//$confdir\//;
    die "LocalBaseDirectory $localsrc is not a directory\n" if ! -d $localdir;
}

my $startage=$opts{s} // $config{startage};
my $endage=$opts{e} // $config{endage};

$config{maxruntime} = ($opts{r}+0) if $opts{r};
$config{pause} = $opts{p} if exists $opts{p};
$config{verbose} = 1 if $verbose;

my $codes=$config{codes};
$codes = join(' ',@$codes) if ref($codes) eq 'ARRAY';
$codes = join(' ',keys %$codes) if ref($codes) eq 'HASH';
my $validcodes={};
my $allcodes=0;
foreach my $c (split(' ',$codes))
{
    $allcodes=1 if $c eq '*';
    $validcodes->{uc($c)} = 1;
}
$allcodes = 1 if ! %$validcodes;

my $remotedir=$config{remotedir};
my $remotefilere=$config{remotefilere};
my $targetpath=$config{targetpath};
my $markerpath=$config{markerpath};
my $commandshell=$config{postdownloadcommandshell};
my $postdownloadcommand=$config{postdownloadcommand};
my $statusfile=$config{statusfile};
my $mintimesincerun=$config{mintimesincelastrun};
my $dochdir=$config{postdownloadcommandchdir};
$dochdir=0 if $dochdir =~ /(no|false)/i;

my $startdate=$startage =~ /^\d+$/ ? "now-$startage" : $startage;
$startdate=parse_gnss_date($startdate);
my $enddate=$endage =~ /^\d+$/ ? "now-$endage" : $endage;
$enddate=parse_gnss_date($enddate);

my $maxruntime=timeToSeconds($config{maxruntime});
my $jobexpirytime = $maxruntime > 0 ? time()+$maxruntime*60 : 0;

my $mintimesincesuccess=0;
my $mintimesincefail=0;
if( $mintimesincerun )
{
    my($minsucc,$minfail)=split(' ',$mintimesincerun);
    $minfail=$minsucc if $minfail eq '';
    $mintimesincesuccess=timeToSeconds($minsucc);
    $mintimesincefail=timeToSeconds($minfail);
}

my $ftp=new FtpConnection( %config );

if( $verbose )
{
    print "------------------------------------------\n";
    print  "Mirror GNSS data       ",strftime("%Y:%m:%d %H:%M:%S",localtime),"\n"; 
    print  "Configuration:         $conffile\n";
    printf "Remote host:           %s\n",$ftp->host;
    printf "Remote user:           %s\n",$ftp->user;
    printf "Remote base dir:       %s\n",$ftp->basedir;
    print  "Remote directory:      $remotedir\n";
    print  "Remote file RE:        $remotefilere\n";
    print  "Local base directory:  $localsrc\n" if ! $bucketname;
    print  "S3 bucket:             $bucketname\n" if $bucketname;
    print  "S3 prefix:             $bucketprefix\n" if $bucketprefix;
    print  "Target file path:      $targetpath\n";
    print  "Marker file path:      $markerpath\n";
    print  "Post download shell    $commandshell\n" if $commandshell;
    print  "Post download command: $postdownloadcommand\n";
    printf "Change dir for pdc   : %s\n",$dochdir ? 'yes' : 'no';
    printf "Start date:            %04d:%03d\n",seconds_yearday($startdate);
    printf "End date:              %04d:%03d\n",seconds_yearday($enddate);
    if( $maxruntime > 0 )
    {
        printf "Max run time:     %.1f minutes\n",$maxruntime;
    }
    if( $allcodes )
    {
        print "Downloading:      all codes\n";
    }
    else
    {
        printf "Downloading:      %d codes\n",scalar(keys %$validcodes);
    }
    printf "FTP timeout:     %s\n",$ftp->timeout;
    if( $mintimesincesuccess || $mintimesincefail )
    {
        printf "Min time since last successful run: %.1f minutes\n",$mintimesincesuccess/60;
        printf "Min time since last failed run:     %.1f minutes\n",$mintimesincefail/60;
    }
}

# Test status file

my $successfile=$statusfile.'.success' if $statusfile;
my $failfile=$statusfile.'.fail' if $statusfile;

if( $statusfile )
{
    if( (-e $successfile && $mintimesincesuccess > $SECS_PER_DAY*(-M $successfile) )
     || (-e $failfile && $mintimesincefail > $SECS_PER_DAY*(-M $failfile) ) )
    {
        if( $verbose )
        {
            print "Skipping download as already done recently\n";
            exit;
        }
    }
    # Get rid of old status files, create a fail file.  Replace
    # with success file if complete successfully.
    unlink($successfile);
    unlink($failfile);
    open(my $ffh, ">$failfile") || die "Cannot create status file $failfile\n";
    close($ffh);
}

# Ensure outputs are flushed to make it easy to monitor progress..
select(STDERR);
$|=1;
select(STDOUT);
$|=1;


$postdownloadcommand =~ s/(^|\s)\~\//$1.$confdir.'\/'/eg;

# @valid_dates is a list of possible date options that can be matched against fields directory/filenames.
# This is the starting point for filtering out the candidate files.

my @valid_dates=();
for( my $i = $startdate; $i <= $enddate; $i += $SECS_PER_DAY )
{
    my($yy,$mm,$dd)=(seconds_ymdhms($i));
    my($yy2,$skip,$ddd)=(time_elements($i));
    push(@valid_dates,{
            yyyy=>sprintf("%04d",$yy),
            yy=>sprintf("%02d",$yy%100),
            mm=>sprintf("%02d",$mm),
            ddd=>sprintf("%03d",$ddd),
            dd=>sprintf("%02d",$dd),
            mmm=>$months[$mm-1],
            MMM=>$umonths[$mm-1],
            Mmm=>$ccmonths[$mm-1],
            mmmm=>$fullmonths[$mm-1],
            MMMM=>$ufmonths[$mm-1],
            Mmmm=>$cfmonths[$mm-1],
        });
}

# @dirparts is an array of components of the remote file path.  Each in turn
# is used to filter down the valid options before passing on to the next directory.

my @dirparts;
foreach my $p ( split(/\//,$remotedir),$remotefilere)
{
    next if $p eq '';
    $p =~ s/\./\\./g;
    $p =~ s/\?/./g;
    $p =~ s/\*/.*/g;
    $p =~ s/\(\.\<(\w+)\>/(?<$1>/g;
    $p =~ s/(\{(\w+)\})/
             exists $patterns{$2} ?
                '(?<'.$2.'>'.$patterns{$2}.')' :
                $1
                /exg;
    $p = '^'.$p.'$';

    my @fields=( $p =~ /\(\?\<(\w+)\>/g );
    push( @dirparts, { re=>qr/$p/, fields=>\@fields });
}

my $localpath=abs_path($localdir);
my $startdir=getcwd;
chdir($localpath);
downloadDir( $ftp, $ftp->basedir, \@valid_dates, \@dirparts );
$ftp->quit();

if( $statusfile )
{
    unlink($failfile);
    open(my $ffh, ">$successfile") || die "Cannot create status file $successfile\n";
    close($successfile);
}

if( $verbose )
{
    print "\nFinished ",strftime("%Y:%m:%d %H:%M:%S",localtime),"\n"; 
    print "------------------------------------------\n";
}

#  filteredOptions:
#
#  $options is an array of currently valid options.  Each is a hash with a set of keys and values that match
#  $dirname is the name to filter the list against
#  $dirpart is the defines the structure of $dirname as a regular expression with named capture groups and a list of 
#     capture group names (fields)
#
#  Each currently valid option is tested against the name.  If all the fields in the name match currently existing
#  value in the option then it passes. Options that pass have any other fields in the name added to them.
#  
#  The field "code" is treated specially and is additionally matched against valid codes

sub filteredOptions
{
    my($options,$dirname,$dirpart) = @_;
    my @options=();
    my $fields=$dirpart->{fields};
    my $re=$dirpart->{re};
    my %fieldvalues=();
    return [] if $dirname !~ /$re/;
    my $code;
    foreach my $f (@$fields)
    {
        $fieldvalues{$f}=$+{$f};
        if(lc($f) eq 'code')
        {
            $fieldvalues{CODE}=uc($fieldvalues{$f});
            $fieldvalues{code}=lc($fieldvalues{$f});
            $fieldvalues{Code}=$fieldvalues{$f};
            $code=$fieldvalues{CODE};
        }
    }

    return [] if $code ne '' && ! $allcodes && ! $validcodes->{$code};

    my @matches=();

    foreach my $opt (@$options)
    {
        my $ok=1;
        foreach my $k (@$fields)
        {
            next if (! exists $opt->{$k}) || ($opt->{$k} eq $fieldvalues{$k});
            $ok = 0;
            last;
        }
        next if ! $ok;
        my %match=%$opt;
        while ( my ($k,$v) = each %fieldvalues ) { $match{$k}=$v; }
        push( @matches, \%match );
    }
    return \@matches;
}

sub expandTarget
{
    my ($opts,$file,$template,$variable,$location)=@_;
    my $result='';
    foreach my $opt (@$opts)
    {
        $opt->{filename} = $file;
        my $value=$template;
        $value =~ s/\{(\w+)\}/$opt->{$1}/eg;
        if( $value =~ /\{\w+\}/ )
        {
            print STDERR "** Unresolved $variable name $value for $location\n";
            return;
        }
        if( $result && $value ne $result )
        {
            print STDERR "** Ambiguous $variable for $location ($result,$value)\n";
            return;
        }
        $result = $value;
    }
return $result;
}

sub downloadDir
{
    my( $ftp, $dirname, $options, $dirparts ) = @_;
    return if $jobexpirytime && time > $jobexpirytime;
    print "Processing $dirname\n" if $verbose;
    if( ! $ftp->cwd($dirname) )
    {
        print STDERR "** Cannot access remote directory $dirname\n";
        return;
    }
    my ($dirs, $files) = $ftp->dirList();
    my @parts=@$dirparts;
    my $dirpart=shift(@parts);

    # If we are not at the list part of $dirparts, then we are matching against directories.
    # Recursively call this routine for valid directories.

    my $expired=0;
    if( @parts )
    {
        return if ! ref $dirs;
        foreach my $dir (@$dirs)
        {
            $expired=1;
            last if $jobexpirytime && time > $jobexpirytime;
            $expired=0;
            my $opts=filteredOptions($options,$dir,$dirpart);
            next if ! @$opts;
            downloadDir( $ftp, "$dirname/$dir", $opts, \@parts );
        }
        print STDERR "** Job terminated - maximum run time expired\n" if $expired;
        return;
    }

    # Otherwise we are matching against files for downloading, so 
    # try each one in turn

    return if ! ref $files;
    my $nfiles=0;
    # Ensure the target directory exists.. 
    my $startdir=getcwd();
    if( ! -d $localpath )
    {
        File::Path::make_path($localpath);
        cwd($localpath);
    }    
    foreach my $file (sort keys %$files)
    {
        $expired=1;
        last if $jobexpirytime && time > $jobexpirytime;
        $expired=0;
        # Does it match the current filtered options
        my $opts=filteredOptions($options,$file,$dirpart);
        next if ! @$opts;

        # Build the target name. There may be more than one filtered option
        # remaining, so make sure that if so they uniquely define a target name.
        # If not then fail the download.

        my $size=$files->{$file}->{size};

        my $target=expandTarget($opts,$file,$targetpath,'target file name',"$dirname/$file");
        my $marker=expandTarget($opts,$file,$markerpath,'marker file name',"$dirname/$file");
        my $command=expandTarget($opts,$file,$postdownloadcommand,'marker file name',"$dirname/$file");

        next if ! $target;

        my $available=0;
        my $tgtpath=$target;
        my $tgtname=$target;
        $tgtpath =~ s/[^\\\/]*$//;
        $tgtpath =~ s/[\\\/]$//;
        $tgtname =~ s/.*[\\\/]//;
        if( ! -d $tgtpath && ! File::Path::make_path($tgtpath) )
        {
            print STDERR "** Cannot create target directory at $tgtpath\n";
            next;
        }

        if( $bucket )
        {
            my $filestat=$bucket->fileStats($target);
            if( $filestat )
            {
                $available=$ignoresize || $filestat->{size} == $size;
            }
            # If not available try and get the marker file 
            if( ! $available && $marker )
            {
                $bucket->getFile($marker,$marker);
            }
        }

        # Now try and download the file
        elsif( -e $target )
        {
            if( ! -f $target )
            {
                print STDERR "** Cannot create file at $target - something is already there\n";
                next;
            }
            # Check the size - if it matches then assume the file is up to date.
            $available=$ignoresize || -s $target == $size;
        }
        if( $available )
        {
            print "$target is already downloaded and of the correct size\n" if $verbose > 1;
            next;
        }

        if( $marker && -f $marker )
        {
            my $markersize=$size;
            if( ! $ignoresize )
            {
                $markersize=0;
                if( open(my $mf, "<$marker") )
                {
                    $markersize=<$mf>+0;
                    close($mf);
                }
            }
            if( $size == $markersize )
            {
                print "$target marker file present and shows correct size\n" if $verbose > 1;
                next;
            }
        }

        # Download to a temporary file first to ensure failed 
        # downloads don't generate incomplete files.

        $nfiles++;
        my $tmp=$tgtpath.'/.download.'.$tgtname.'.tmp';
        unlink($tmp);

        if( ! $ftp->get($file,$tmp) )
        {
            print STDERR "** Failed to download $dirname/$file\n";
            print STDERR $ftp->message,"\n";
            unlink($tmp);
        }
        elsif( ! move($tmp,$target) )
        {
            print STDERR "** Failed to overwrite $target\n";
            unlink($tmp);
        }
        else
        {
            print "Successfully downloaded $target\n" if $verbose;
            print "$target\n" if $listfiles;
            if( $command && $commandshell )
            {
                my $cwd=getcwd;
                chdir($tgtpath) if $dochdir;
                print "Running postdownload script with $commandshell";
                eval
                {
                    open(my $shell, "| $commandshell" ) || die "Cannot execute $commandshell\n";
                    print $shell $command;
                    close($shell);
                };
                if( $@ )
                {
                    print STDERR $@;
                }
                chdir($cwd);
            }
            elsif( $command )
            {
                print "Running $command\n" if $verbose;
                my $cwd=getcwd;
                chdir($tgtpath) if $dochdir;
                foreach my $cmdline (split(/\n/,$command) )
                {
                    my @command=split(' ',$cmdline);
                    next if ! @command;
                    next if $command =~ /^\s*\#/;
                    eval
                    {
                        system(@command);
                    };
                    if( $@ )
                    {
                        print STDERR $@;
                    }
                }
                chdir($cwd);
            }
            if( $marker )
            {
                open(my $mf, ">$marker" );
                print $mf $size;
                close($mf);
            }
        }
    }
    if( $bucket && $nfiles > 0 )
    {
        my $error;
        $bucket->syncToBucket($localpath,'/',delete=>1);
        # keep_root doesn't avoid error trying to delete with cwd as root directory?
        chdir($startdir);
        File::Path::remove_tree($localpath,{keep_root=>1,error=>\$error});
    }
    print STDERR "** Job terminated - maximum run time expired\n" if $expired;
}

# Simplistic parsing of a directory listing.
#
# Assumes that directory and file names do not include space characters!
#
# Returns a list of direcories, and a hash of files keyed on the filename and
# having value the same as the directory entry

sub printExampleConfig
{
    my $started = 0;
    while( my $l = <DATA> )
    {
        $started=1 if $l =~ /^\s*\#/;
        next if ! $started;
        $l =~ s/^\s+//;
        $l = "\n" if $l eq '';
        print $l;
    }
}

#========================================================================

package FtpConnection;

sub new
{
    my ($class, %config) = @_;

    my $self={};
    $self->{verbose}=$config{verbose};
    $self->{remoteuri}=$config{remoteuri};
    $self->{user}=$config{remoteuser};
    $self->{password}=$config{remotepassword};
    $self->{timeout}=$config{timeout}+0 || 30;
    $self->{pause}=$config{downloadwait}+0 || 1; 
    $self->{reconnectwait}=$config{reconnectwait}+0 || 5;
    $self->{maxreconnect}=$config{maxreconnectiontries}+0 || 5;
    $self->{maxdownloads}=$config{maxdownloadsperconnection}+0 || 5;

    my $remoteuri=$self->{remoteuri};
    my $uri=URI->new($remoteuri);
    die "$remoteuri is not a valid FTP URI.\nMust be an ftp:// URI" if $uri->scheme != 'ftp';

    my $host=$uri->host;
    my $basedir=$uri->path;
    my ($uri_user,$uri_pwd) = split(/\:/,$uri->userinfo,2);

    $self->{host}=$host;
    $self->{user}=$uri_user if $uri_user;
    $self->{password}=$uri_pwd if $uri_pwd;
    $self->{basedir}=$basedir;

    $self->{_ftp} = undef;
    $self->{_dir} = $basedir;
    $self->{_ndownload} = 0;

    return $self=bless $self, $class;
}

sub verbose { return $_[0]->{verbose}; }
sub remoteuri { return $_[0]->{remoteuri}; }
sub host { return $_[0]->{host}; }
sub user { return $_[0]->{user}; }
sub password { return $_[0]->{password}; }
sub timeout { return $_[0]->{timeout}; }
sub pause { return $_[0]->{pause}; }
sub reconnectwait { return $_[0]->{reconnectwait}; }
sub maxreconnect { return $_[0]->{maxreconnect}; }
sub maxdownloads { return $_[0]->{maxdownloads}; }
sub basedir { return $_[0]->{basedir}; }

sub ftp
{
    my( $self, $force ) = @_;
    return $self->{_ftp} if $self->{_ftp} && ! $force;
    $self->quit;
    my $trying=$self->maxreconnect;
    $trying=1 if $trying < 1;
    my $host=$self->host;
    my $ftp;
    while( $trying-- )
    {
        print "Connecting to $host\n" if $self->verbose;
        $ftp=Net::FTP->new($host, Timeout=>$self->timeout);
        last if $ftp;
        Time::HiRes::usleep( $self->reconnectwait * 1000000) if $trying;
    }

    if( ! $ftp )
    {
        die "Cannot make FTP connection to $host\n";
    }

    my $user=$self->user;
    my $password=$self->password;
    my $basedir=$self->basedir;

    $ftp->login($user,$password) || die "Cannot login to $host as $user to $host\n";
    $ftp->binary();
    $ftp->cwd($self->{_dir}) || die "Cannot cd to $basedir on $host\n";
    $self->{_ftp} = $ftp;
    return $ftp;
}

sub quit
{
    my( $self)=@_;
    $self->{_ftp}->quit() if $self->{_ftp};
    $self->{_ftp} = undef;
}

sub reconnect
{
    my( $self)=@_;
    $self->quit;
    Time::HiRes::usleep( $self->reconnectwait * 1000000 );
}

sub run
{
    my( $self, $sub )=@_;
}

sub cwd
{
    my( $self, $dir) = @_;
    $self->{_dir} = $dir;
    return $self->ftp->cwd($dir);
}

sub dirList
{
    my ($self) = @_;
    return $self->parseDir( $self->ftp->dir() );
}

sub size
{
    my ($self,$file) = @_;
    return $self->ftp->size($file);
}

sub get
{
    my ($self,$file,$target) = @_;
    if( $self->maxdownloads > 0 && $self->{_ndownload} >= $self->maxdownloads )
    {
        $self->reconnect;
        $self->{_ndownload} = 0;
    }
    Time::HiRes::usleep( $self->pause * 1000000 ) if $self->{_ndownload};
    my $ntries=0;
    my $success=0;
    while( 1 )
    {

        $success=$self->ftp->get($file,$target);
        last if $success;
        last if $ntries++ >= $self->maxreconnect;
        print "** Download of $file failed - reconnecting\n" if $self->verbose;
        $self->reconnect;
    }
    if( $success )
    {
        $self->{_ndownload}++;
        my $mtime=$self->ftp->mdtm( $file );
        utime $mtime,$mtime,$target if $mtime;
    }
    else
    {
        print "** Download of $file failed\n".$self->ftp->message."\n" 
            if $self->verbose && ! $success;
    }
    return $success;
}

sub parseDir
{
    my($self,@listing)=@_;
    my $dirs=[];
    my $files={};
    @listing=@{$listing[0]} if ref $listing[0];
    foreach my $l (@listing)
    {
        $l =~ s/^\s+//;
        $l =~ s/\s+$//;
        # <DIR> is Microsoft server test
        my $isdir=$l=~/^d/ || $l =~ /\<DIR\>/;
        my $name=(split(' ',$l))[-1];
        # Skip names starting with '.";
        next if $name eq '';
        next if $name =~ /^\./;
        if( $isdir )
        {
            push(@$dirs,$name);
        }
        else
        {
            # Select column based on unix or MS format listing
            my $sizecol =  $l =~ /^\d\d/ ? -2 : 4;
            my $size=(split(' ',$l))[$sizecol];
            $files->{$name}={size=>$size, dir=>$l };
        }
    }
    return $dirs,$files;
}

#========================================================================
__END__

=head2 Example configuration file
 
 # Example configuration file:
 #
 # Note all configuration item values can contain references to other configuration
 # item values as {xxxxx}, where xxx is the other item.  But note special values
 # for date components and file names that should not be used.
 #
 # {xxxx} strings that are not matched can be replaced by environment variables if
 # they exist, except for the code and time patterns listed below, which are 
 # replaced with components of the file path.
 #
 # {ENV:xxx} can be used to explicitly replace environment variables.
 #
 # Configuration items can be included from another file using:
 #
 # include filename
 #
 # Filenames are relative to this configuration file.
 
 # RemoteUri is the the base of the remote directory
 
 RemoteUri=ftp://ftp.geonet.org.nz/rawgps
 
 RemoteUser=anonymous
 
 RemotePassword=positionz@linz.govt.nz
 
 TimeOut 30
 
 # Delay in seconds added after each successful download to be polite to server
 
 DownloadWait 1

 # If a download fails the script will try to reconnect to the server
 # The following options control the reconnection 
 
 MaxReconnectionTries 5

 # Time delay in seconds between reconnection attempts

 ReconnectionWait 5

 # Auto reconnect after specified number of downloads
 
 MaxDownloadsPerConnection 100

 # Maximum runtime in minutes - once this time has expired the job will finish
 
 MaxRunTime 120

 # StatusFile - if this is defined then at the completion of the run there
 # will be a file named either xxx.success or xxx.fail.  The age of this can
 # be tested with the MinTimeSinceLastRun option.  This specifies either a 
 # single time, or two times (since success and since failure).  Time can
 # be followed by h or d for hours or days (eg 5d).  Default is hours.  
 # If the script is run sooner than the minimum time then it will stop 
 # immediately.
 
 # StatusFile .mirror_status
 # MinTimeSinceLastRun 7d 4
 
 # RemoteDir is the path to the files to download.
 #
 # Can include {yyyy},{yy},{mmmm}, {mmm},{mm},{ddd},{dd} which will map to 
 # the corresponding date strings (mmm is 3 letter month name, mmmm is the 
 # full month name). Will also accept Mmm, MMM, Mmmm, MMMM for different 
 # capitalisation.

 # Also can accept {code} or {CODE} for upper or lower case four character
 # codes which will match a valid code. Use {Code} for a case insensitive
 # code match.
 # 
 # These will be replaced with values corresponding to the maximum number
 # of days before the current date to process.  Can also include ? for any
 # character, and * for any set of characters.
 
 RemoteDir=/{yyyy}/{ddd}
 
 # RemoteFileRe.  Remote file names are matched against this regular expression.
 # Files that match are candidates for downloading.  
 # This can include any of the time and code components, eg {ddd}. Also it
 # can include regular expression # capture groups (?<xxx>...) to capture 
 # fields that can be used in the target path.  
 
 RemoteFileRe={code}{yyyy}\d{8}[a-z].T02
 
 # Local base directory.  All files downloaded or created by subsequent scripts
 # should be subdirectories of this directory. Use ~ for the directory in which
 # the configuration script is located.  This is not used if the target is an S3
 # bucket.  However the script will create a temporary local directory for retrieving
 # and processing files prior to uploading to S3. 
 #
 # All local filenames below are relative to this (or on S3, relative to the S3 prefix)
 # Post download script are run from this directory unless PostDownloadCommandChDir 
 # is true.
 
 LocalBaseDirectory ~

 # If an S3 bucket is defined then files are installed into the bucket using the 
 # file structure relative to the LocalBaseDirectory.  The file names can be prefixed
 # with a common prefix to generate the corresponding S3 bucket key.  S3 settings
 # are as used by the LINZ::GNSS::AwsS3Bucket module.  

 # s3_bucket my_bucket
 # s3_prefix ${subdir}${subdir?/}

 # Target directory relative to the base directory.
 # Can include time components
 # as for RemotePath.  Can also include {filename} to use the source filename.
 
 TargetPath={yyyy}/{ddd}/{filename}

 # Marker file.  By default the script checks for the existence of the target 
 # file.  If it exists and is of the correct size it is not downloaded again.  The 
 # script can instead use a marker file defined below.  It it read to determine
 # if the file has been downloaded and the size of the file.

 MarkerPath={yyyy}/{ddd}/{filename}.downloaded

 # Processing script. Command(s) to run once a file has been downloaded.  The script
 # is run in the target directory.  The command can include parameters, and can
 # include the replacement strings for filename, code, etc.
 #
 # If PostDownloadCommandChDir evaluates to true then the script changes to the 
 # download directory to execute the command(s).
 
 PostDownloadCommand process_downloaded_file.sh {filename}
 PostDownloadCommandChDir 1
 
 # Codes to download.  Use Codes * (or omit codes altogether), to download
 # all available codes.
 
 Codes KAIK RGRE
 Codes SCTB
 
 # Number of days before current date to start and end download
 
 StartAge 30
 EndAge 0
